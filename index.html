<!DOCTYPE HTML>
<!-- saved from url=(0041)https://people.eecs.berkeley.edu/~barron/ -->
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <!-- DELETE THIS SCRIPT if you use this HTML, otherwise my analytics will track your page -->
  <!-- Global site tag (gtag.js) - Google Analytics -->  
  <meta name="author" content="Ying WEI">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */


/* latin-ext */
@font-face {
  font-family: 'Lato';
  font-style: italic;
  font-weight: 400;
  src: local('Lato Italic'), local('Lato-Italic'), url(https://fonts.gstatic.com/s/lato/v15/S6u8w4BMUTPHjxsAUi-qNiXg7eU0.woff2) format('woff2');
  unicode-range: U+0100-024F, U+0259, U+1E00-1EFF, U+2020, U+20A0-20AB, U+20AD-20CF, U+2113, U+2C60-2C7F, U+A720-A7FF;
}
/* latin */
@font-face {
  font-family: 'Lato';
  font-style: italic;
  font-weight: 400;
  src: local('Lato Italic'), local('Lato-Italic'), url(https://fonts.gstatic.com/s/lato/v15/S6u8w4BMUTPHjxsAXC-qNiXg7Q.woff2) format('woff2');
  unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD;
}
/* latin-ext */
@font-face {
  font-family: 'Lato';
  font-style: italic;
  font-weight: 700;
  src: local('Lato Bold Italic'), local('Lato-BoldItalic'), url(https://fonts.gstatic.com/s/lato/v15/S6u_w4BMUTPHjxsI5wq_FQftx9897sxZ.woff2) format('woff2');
  unicode-range: U+0100-024F, U+0259, U+1E00-1EFF, U+2020, U+20A0-20AB, U+20AD-20CF, U+2113, U+2C60-2C7F, U+A720-A7FF;
}
/* latin */
@font-face {
  font-family: 'Lato';
  font-style: italic;
  font-weight: 700;
  src: local('Lato Bold Italic'), local('Lato-BoldItalic'), url(https://fonts.gstatic.com/s/lato/v15/S6u_w4BMUTPHjxsI5wq_Gwftx9897g.woff2) format('woff2');
  unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD;
}
/* latin-ext */
@font-face {
  font-family: 'Lato';
  font-style: normal;
  font-weight: 400;
  src: local('Lato Regular'), local('Lato-Regular'), url(https://fonts.gstatic.com/s/lato/v15/S6uyw4BMUTPHjxAwXiWtFCfQ7A.woff2) format('woff2');
  unicode-range: U+0100-024F, U+0259, U+1E00-1EFF, U+2020, U+20A0-20AB, U+20AD-20CF, U+2113, U+2C60-2C7F, U+A720-A7FF;
}
/* latin */
@font-face {
  font-family: 'Lato';
  font-style: normal;
  font-weight: 400;
  src: local('Lato Regular'), local('Lato-Regular'), url(https://fonts.gstatic.com/s/lato/v15/S6uyw4BMUTPHjx4wXiWtFCc.woff2) format('woff2');
  unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD;
}
/* latin-ext */
@font-face {
  font-family: 'Lato';
  font-style: normal;
  font-weight: 700;
  src: local('Lato Bold'), local('Lato-Bold'), url(https://fonts.gstatic.com/s/lato/v15/S6u9w4BMUTPHh6UVSwaPGQ3q5d0N7w.woff2) format('woff2');
  unicode-range: U+0100-024F, U+0259, U+1E00-1EFF, U+2020, U+20A0-20AB, U+20AD-20CF, U+2113, U+2C60-2C7F, U+A720-A7FF;
}
/* latin */
@font-face {
  font-family: 'Lato';
  font-style: normal;
  font-weight: 700;
  src: local('Lato Bold'), local('Lato-Bold'), url(https://fonts.gstatic.com/s/lato/v15/S6u9w4BMUTPHh6UVSwiPGQ3q5d0.woff2) format('woff2');
  unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD;
}



    a {
    color: #2ca25f; /*#1772d0;07889b*/
    text-decoration:none;
    }
    a:focus, a:hover {
    color: #E76F51; /*#f7b733;*/ /*f09228;*/
    text-decoration:none;
    }
    body,td,th,tr,p,a {
    font-family: 'Lato', Verdana, Helvetica, sans-serif; /*'Lato', Verdana, Helvetica, sans-serif;*/
    font-size: 15px; /*14*/
    }
    newsdate {
    font-family: 'Lato', Verdana, Helvetica, sans-serif; /*'Lato', Verdana, Helvetica, sans-serif;*/
    font-size: 15px; /*14*/
    color: #E76F51;
    }
    strong {
    font-family: 'Lato', Verdana, Helvetica, sans-serif; /*'Lato', Verdana, Helvetica, sans-serif;*/
    font-size: 15px; /*14*/
    }
    heading {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;  /*'Lato', Verdana, Helvetica, sans-serif;*/
    font-size: 22px;
    color: #E76F51; /*#fc4a1a;e37222*/
    }
    heading2 {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;  /*'Lato', Verdana, Helvetica, sans-serif;*/
    font-size: 18px;
    }
    papertitle {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;  /*'Lato', Verdana, Helvetica, sans-serif;*/
    font-size: 15px; /*14*/
    font-weight: 700;
    }
    name {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;  /*'Lato', Verdana, Helvetica, sans-serif;*/
    font-size: 42px;
    }
    li:not(:last-child) {
        margin-bottom: 5px;
    }
    .one
    {
    width: 160px;
    height: 160px;
    position: relative;
    }
    .two
    {
    width: 160px;
    height: 160px;
    position: absolute;
    transition: opacity .2s ease-in-out;
    -moz-transition: opacity .2s ease-in-out;
    -webkit-transition: opacity .2s ease-in-out;
    }
    .fade {
     transition: opacity .2s ease-in-out;
     -moz-transition: opacity .2s ease-in-out;
     -webkit-transition: opacity .2s ease-in-out;
    }
    span.highlight {
        background-color: #ffffd0;
    }

    .header {
  overflow: hidden;
  background-color: white;
  padding: 10px 10px;
}

/* Style the header links */
.header a {
  float: left;
  color: #2ca25f;
  text-align: center;
  padding: 12px;
  text-decoration: none;
  font-size: 17px;
  line-height: 25px;
  border-radius: 4px;
}

/* Style the logo link (notice that we set the same value of line-height and font-size to prevent the header to increase when the font gets bigger */
.header a.logo {
  font-size: 25px;
  font-weight: bold;
}

/* Change the background color on mouse-over */
.header a:hover {
  background-color: white;
  color: #E76F51;
}

/* Style the active/current link*/
/*.header a.active {
  background-color: white;
  color: #0074E1;
}*/

/* Float the link section to the right */
.header-right {
  float: right;
}

/* Add media queries for responsiveness - when the screen is 500px wide or less, stack the links on top of each other */
@media screen and (max-width: 500px) {
  .header a {
    float: none;
    display: block;
    text-align: left;
  }
  .header-right {
    float: none;
  }
}

  </style>
  <title>Ying WEI</title>
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <!--- link rel="icon" type="image/png" href="images/seal_icon.png" -->

    <style id="dark-reader-style" type="text/css">@media screen {

/* Leading rule */
html {
  -webkit-filter: brightness(110%) contrast(90%) grayscale(20%) sepia(10%) !important;
}

/* Text contrast */
html {
  text-shadow: 0 0 0 !important;
}

/* Full screen */
*:-webkit-full-screen, *:-webkit-full-screen * {
  -webkit-filter: none !important;
}

/* Page background */
html {
  background: #FFFAF0 !important;
}

}</style>

<script type="text/javascript">
   function visibility_on(id) {
        var e = document.getElementById(id+"_text");
        if(e.style.display == 'none')
            e.style.display = 'block';
        var e = document.getElementById(id+"_img");
        if(e.style.display == 'none')
            e.style.display = 'block';
   }
   function visibility_off(id) {
        var e = document.getElementById(id+"_text");
        if(e.style.display == 'block')
            e.style.display = 'none';
        var e = document.getElementById(id+"_img");
        if(e.style.display == 'block')
            e.style.display = 'none';
   }
   function toggle_visibility(id) {
       var e = document.getElementById(id+"_text");
       if(e.style.display == 'inline')
          e.style.display = 'block';
       else
          e.style.display = 'inline';
       var e = document.getElementById(id+"_img");
       if(e.style.display == 'inline')
          e.style.display = 'block';
       else
          e.style.display = 'inline';
   }
   function toggle_vis(id) {
       var e = document.getElementById(id);
       if (e.style.display == 'none')
           e.style.display = 'inline';
       else
           e.style.display = 'none';
   }
</script>
</head>

  <body><div id="StayFocusd-infobar" style="display: none; top: 2400px;">
    <img src="chrome-extension://laankejkbhbdhmipfmgcngdelahlfoji/common/img/eye_19x19_red.png">
    <span id="StayFocusd-infobar-msg"></span>
    <span id="StayFocusd-infobar-links">
        <a id="StayFocusd-infobar-never-show">hide forever</a>&nbsp;&nbsp;|&nbsp;&nbsp;
        <a id="StayFocusd-infobar-hide">hide once</a>
    </span>
</div>
<body><div class="header" style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
  <div class="header-right">
    <a href="https://wei-ying.net/index.html">Home</a>
    <!-- <a href="https://wei-ying.net/teaching.html">Teaching</a> -->
  </div>
</div>

  
<table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <hr><table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
        <p align="center">
        <name>Ying WEI (魏 颖)</name><br>
        ying.wei [at] ntu [dot] edu [dot] sg
        </p>
        <p>I am currently a <a href="https://www.ntu.edu.sg/research/research-careers/nanyang-assistant-professorship-(nap)#Content_C003_Col00">Nanyang Assistant Professor</a> with <a href="https://www.cs.cityu.edu.hk/">School of Computer Science and Engineering, Nanyang Technological University</a>.
        </p>
        <p style="text-align: justify;">
        I am generally interested in developing algorithms that equip machines with more general intelligence via knowledge transfer and compositionality.
        This includes allowing continuous transfer and adaptation of the knowledge previous learned (nowadays in LLMs) to quickly learn the current task with minimal human supervision, and autonomously evaluating the success of knowledge transfer. I am also passionate about applying these algorithms into real-world applications with small data, e.g., drug discovery.
        </p>
        <p style="text-align: justify;">
        Previously, I was an Assistant Professor at <a href="https://www.cs.cityu.edu.hk/">Department of Computer Science, City University of Hong Kong</a> and 
        a senior researcher at <a href="https://ai.tencent.com/ailab/zh/index">Tencent AI Lab</a>. I completed my Ph.D. in Computer Science and Engineering at <a href="https://www.ust.hk/home/">Hong Kong University of Science and Technology</a> under the supervision of Professor <a href="http://www.cs.ust.hk/~qyang/">Qiang Yang</a>, and my B.S. in Automation at <a href="http://www.hust.edu.cn/">Huazhong University of Science and Technology</a>. I have also spent time interning at <a href="https://www.msra.cn/">Microsoft Research Asia</a>.
        </p>

         <strong style="text-align: justify;">
        I am looking for highly-motivated full-time PhD students, post-doctoral research fellows, and also research assistants!</strong>
        </p>
        </p>
        <p align="center">

<!--<a href="data/updated_CV_tex.pdf">CV</a> &nbsp;/&nbsp;-->
<!--<a href="https://people.eecs.berkeley.edu/~cbfinn/bio.txt">Bio</a> &nbsp;/&nbsp;-->
<a href="https://lbezone.ust.hk/pdfviewer/web/viewer.html?file=aHR0cHM6Ly9sYmV6b25lLnVzdC5oay9vYmovMS9vLzk5MTAxMjU1NDg2NzMwMzQxMi85OTEwMTI1NTQ4NjczMDM0MTIucGRm#page=1">PhD Thesis</a> &nbsp;/&nbsp;
<!--<a href="https://scholar.google.com/citations?hl=en&amp;user=1xw2vTsAAAAJ">Google Scholar</a> &nbsp;/&nbsp;-->
<!--<a href="http://www.github.com/cbfinn/"> GitHub </a> &nbsp;/&nbsp;-->
<a href="https://www.linkedin.com/in/ying-wei-81435159/">LinkedIn</a> &nbsp;/&nbsp;
<!--<a href="https://scholar.google.com/citations?hl=en&amp;user=1xw2vTsAAAAJ">Google Scholar</a> &nbsp;/&nbsp;-->
<!--<a href="http://www.github.com/cbfinn/"> GitHub </a> &nbsp;/&nbsp;-->
<a href="https://scholar.google.com/citations?hl=en&user=5UpFdKsAAAAJ">Google Scholar</a> 
        </p>
        </td>
        <td width="30%">
        <img src="images/Ying_circle_2.png">
        </td>
      </tr>
  </tbody></table>



      <!-- NEWS SECTION -->
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tbody></tbody><td width="100%" valign="middle">

        <table width="100%" cellpadding="3"><tbody>
          <tr>
            <td style="width: 30px; padding-left: 0px; padding-bottom: 10px;">
              <img width="35px" src="./images/news.png">
            </td>
            <td style="padding-bottom: 10px;"><heading>News</heading></td>
          </tr>
        </tbody></table>

      <div style="overflow-y: scroll; padding-right: 1px; height:165px;">
      <ul>
        <!--<h3 id="2019">2019</h3>-->
        <li> [<newsdate>July 2024</newsdate>] We are organizing the NeurIPS 2024 Workshop on Compositional Learning! For more information, please visit <a href="https://compositional-learning.github.io/">our website</a>.</li>
        <li> [<newsdate>July 2024</newsdate>] We are organizing the NeurIPS 2024 Workshop on Advancements In Medical Foundation Models! For more information, please visit <a href="https://aim-fm-24.github.io/NeurIPS/">our website</a>.</li>
        <li> [<newsdate>May 2024</newsdate>] Our paper "Understanding and Patching Compositional Reasoning in LLMs" was accepted by ACL 2024 Findings!</li>
        <li> [<newsdate>May 2024</newsdate>] Our paper "Benchmarking and Improving Compositional Generalization of Multi-aspect Controllable Text Generatio" was accepted by ACL 2024!</li>
        <li> [<newsdate>May 2024</newsdate>] Honored to receive the ICLR 2024 Outstanding Honorable Mention!</li>
        <li> [<newsdate>May 2024</newsdate>] Our paper "Unleashing the Power of Meta-tuning for Few-shot Generalization Through Sparse Interpolated Experts" was accepted by ICML 2024!</li>
        <li> [<newsdate>May 2024</newsdate>] Our paper "One Meta-tuned Transformer is What You Need for Few-shot Learning" was accepted by ICML 2024!</li>
        <li> [<newsdate>May 2024</newsdate>] Our paper "Mitigating Catastrophic Forgetting in Online Continual Learning by Modeling Previous Task Interrelations" was accepted by ICML 2024!</li>
        <li> [<newsdate>May 2024</newsdate>] Our paper "Federated Continual Learning via Prompt-based Dual Knowledge Transfer" was accepted by ICML 2024!</li>
        <li> [<newsdate>Apr 2024</newsdate>] Serving as an Area Chair for NeurIPS 2024</li>
        <li> [<newsdate>Feb 2024</newsdate>] Our paper "MoPE-CLIP: Structured Pruning for Efficient Vision-Language Models with Module-wise Pruning Error Metric" was accepted by CVPR 2024!</li>
        <li> [<newsdate>Jan 2024</newsdate>] Our paper "Meta Continual Learning Revisited: Implicitly Enhancing Online Hessian Approximation via Variance Reduction" was accepted by ICLR 2024 (oral)!</li>
        <li> [<newsdate>Jan 2024</newsdate>] Our paper "Gradual Domain Adaptation via Gradient Flow" was accepted by ICLR 2024 (spotlight)!</li>
        <li> [<newsdate>Jan 2024</newsdate>] Our paper "Active Retrosynthetic Planning Aware of Route Quality" was accepted by ICLR 2024!</li>
        <li> [<newsdate>Jan 2024</newsdate>] Serving as an Area Chair for ICML 2024</li>
        <li> [<newsdate>Jan 2024</newsdate>] Serving as an Action Editor for Transactions on Machine Learning Research (TMLR)</li>
        <li> [<newsdate>Jan 2024</newsdate>] Our paper "RetroOOD: Understanding Out-of-Distribution Generalization in Retrosynthesis Prediction" was accepted by AAAI 2024!</li>
        <li> [<newsdate>Sep 2023</newsdate>] Our paper "Towards Anytime Fine-tuning: Continually Pre-trained Language Models with Hypernetwork Prompts" was accepted by EMNLP 2023</li>
        <li> [<newsdate>Sep 2023</newsdate>] Our paper "Secure Out-of-Distribution Task Generalization with Energy-Based Models" was accepted by NeurIPS 2023</li>
        <li> [<newsdate>Sep 2023</newsdate>] Our paper "Does Continual Learning Meet Compositionality? New Benchmarks and An Evaluation Framework" was accepted by NeurIPS 2023</li>
        <li> [<newsdate>Sep 2023</newsdate>] I joined Nanyang Technological University as a Nanyang Assistant Professor</li>
        <li> [<newsdate>July 2023</newsdate>] Our paper "Concept-wise Fine-tuning Matters in Preventing Negative Transfer" was accepted by ICCV 2023</li>
        <li> [<newsdate>Apr 2023</newsdate>] Our paper "Learning to Substitute Spans towards Improving Compositional Generalization" was accepted by ACL 2023</li>
  <!--       <li> [<newsdate>Sep 2022</newsdate>] Our paper "Adversarial Task Up-sampling for Meta-learning" was accepted by NeurIPS 2022</li>
        <li> [<newsdate>Sep 2022</newsdate>] Our paper "Improving Task-Specific Generalization in Few-Shot Learning via Adaptive Vicinal Risk Minimization" was accepted by NeurIPS 2022</li>
        <li> [<newsdate>Sep 2022</newsdate>] Our paper "GRASP: Navigating Retrosynthetic Planning with Goal-driven Policy" was accepted by NeurIPS 2022</li>
        <li> Serving as an area chair for MetaLearn 2022@NeurIPS 2022</li>
        <li> Serving as a program committee member for ICLR 2023</li>
        <li> Serving as a senior program committee member for AAAI 2023</li>
        <li> [<newsdate>May 2022</newsdate>] Our paper "Frustratingly Easy Transferability Estimation" was accepted by ICML 2022</li>
        <li> [<newsdate>May 2022</newsdate>] Our paper "The Role of Deconfounding in Meta-learning" was accepted by ICML 2022</li>
        <li> [<newsdate>Mar 2022</newsdate>] We are organizing ICML 2022 Workshop on <a href="https://pretraining.github.io/">Pre-training: Perspectives, Pitfalls, and Paths Forward</a></li>
        <li> [<newsdate>Dec 2021</newsdate>] I gave an invited talk at  <a href="https://meta-learn.github.io/2021/">MetaLearn 2021@NeurIPS 2021</a> 
        <li> [<newsdate>Oct 2021</newsdate>] I was selected to receive a NeurIPS 2021 Outstanding Reviewer Award given to the top 8% of reviewers  </li>
        <li> [<newsdate>Sep 2021</newsdate>] Our paper "Meta-learning with an Adaptive Task Scheduler" was accepted by NeurIPS 2021</li>
        <li> [<newsdate>Sep 2021</newsdate>] Our paper "Functionally Regionalized Knowledge Transfer for Low-resource Drug Discovery" was accepted by NeurIPS 2021</li>
        <li> Serving as a program committee member for ICLR 2022</li>
        <li> [<newsdate>Sep 2021</newsdate>] Our paper "MetaTS: Meta Teacher-Student Network for Multilingual Sequence Labeling with Minimal Supervision" was accepted by EMNLP 2021</li>
        <li> Serving as a senior program committee member for AAAI 2021</li>
        <li> [<newsdate>Aug 2021</newsdate>] I gave a talk titled "How to Promote the Generalization of a Pre-trained Model" at FTL-IJCAI'21</li>
        <li> Serving as a program committee member for NeurIPS 2021</li>
        <li> [<newsdate>May 2021</newsdate>] Our paper "Improving Generalization in Meta-learning via Task Augmentation" was accepted by ICML 2021</li>
        <li> [<newsdate>May 2021</newsdate>] Our paper "Meta-learning Hyperparameter Performance Prediction with Neural Processes" was accepted by ICML 2021</li>
        <li> [<newsdate>Feb 2021</newsdate>] I joined City University of Hong Kong as an Assistant Professor</li> -->
<!--         <li> Serving as a program committee member for ICML 2021</li>
        <li> Serving as a senior program committee member for AAAI 2021</li>
        <li> Serving as a program committee member for ICLR 2021</li>
        <li> Serving as a program committee member for WWW 2021</li>
         <li> Our paper "Learn to Cross-lingual Transfer with Meta Graph Learning Across Heterogeneous Languages" was accepted by EMNLP 2020</li>
        <li> Our paper "Self-Supervised Graph Transformer on Large-Scale Molecular Data" was accepted by NeurIPS 2020</li>
        <li> Our paper "Adversarial Sparse Transformer for Time Series Forecasting" was accepted by NeurIPS 2020</li>
        <li> Our paper "Collaborative Unsupervised Domain Adaptation for Medical Image Diagnosis" was accepted by IEEE Transactions on Image Processing</li> -->
<!--         <li> Our paper "TranSlider: Transfer Ensemble Learning from Exploitation to Exploration" was accepted by KDD 2020</li>
        <li> Serving as a program committee member for ECML/PKDD 2020</li>
        <li> Serving as a program committee member for NeurIPS 2020</li>
        <li> Serving as a program committee member for ICML 2020</li>
        <li> Our paper "Graph Few-shot Learning via Knowledge Transfer" was accepted by AAAI 2020</li>
        <li> Serving as a program committee member for IJCAI 2020</li>
        <li> Serving as a program committee member for WWW 2020</li>
        <li> Our paper "Transferable Neural Processes for Hyperparameter Optimization" was accepted by the <a href="http://metalearning.ml/2019/">Meta Learning</a> workshop at NeurIPS 2019
        <li> Our paper "Graph Few-shot Learning via Knowledge Transfer" was accepted by the <a href="http://grlearning.github.io">Graph Representation Learning</a> workshop at NeurIPS 2019
        <li> Serving as a reviewer for ICLR 2020</li>
        <li> Recognized as one of the highest-scoring reviewers for NeurIPS 2019
        <li> Serving as a senior program committee member for AAAI 2020
        <li> Invited to be a session chair for IJCAI 2019
        <li> Our paper "Hierarchically-structured Meta-learning" was accepted by ICML 2019 -->


      </ul>
      </div>
      </td></tbody>
      </table>



<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
<tbody>
<td width="100%" valign="middle">
            <table width="100%" cellpadding="3"><tbody>
          <tr>
            <td style="width: 30px; padding-left: 0px; padding-bottom: 0px;">
              <img width="35px" src="./images/pub.png">
            </td>
            <td style="padding-bottom: 0px;"><heading>Publications</heading></td>
          </tr>
        </tbody></table>

            <br><br>
            ( <u>___</u>: equal contribution, *:  corresponding author) <br><br>


              <div onmouseover="document.getElementById('creme').style.display = 'block';"
                onmouseout="document.getElementById('creme').style.display='none';">
                <papertitle>Understanding and Patching Compositional Reasoning in LLMs</papertitle></a><br>
                Zhaoyi Li, Gangwei Jiang, Hong Xie, <a href="https://sites.google.com/site/aisquaredlab/">Linqi Song</a>, <a href="http://staff.ustc.edu.cn/~liandefu/">Defu Lian*</a>, <i>Ying Wei*</i>
              <br>
              <em> Sixty-second Annual Meeting of the Association for Computational Linguistics (ACL) Findings</em>, 2024 <br>
              <a href="https://arxiv.org/pdf/2402.14328v1">pdf</a>  / <a href="https://github.com/Zhaoyi-Li21/creme">code</a>
              </div>
              <div id="creme" style="display:none">
              This paper is among the first to reveal that in LLMs implicit reasoning results indeed surface within middle layers and play a causative role in shaping the final explicit reasoning results. The findings support us to develop CREME,  a lightweight method to patch errors in compositional reasoning via editing the located MHSA modules. Our empirical evidence stands testament to CREME’s effectiveness, paving the way for autonomously and continuously enhancing compositional reasoning capabilities in LLMs.
              </div><br>


              <div onmouseover="document.getElementById('tianqi').style.display = 'block';"
                onmouseout="document.getElementById('tianqi').style.display='none';">
                <papertitle>Benchmarking and Improving Compositional Generalization of Multi-aspect Controllable Text Generation</papertitle></a><br>
                <u>Tianqi Zhong</u>, <u>Zhaoyi Li</u>, Quan Wang, <a href="https://sites.google.com/site/aisquaredlab/">Linqi Song</a>, <i>Ying Wei</i>, <a href="http://staff.ustc.edu.cn/~liandefu/">Defu Lian</a>, <a href="https://faculty.ustc.edu.cn/maozhendong/en/index.htm">Zhendong Mao*</a>.
              <br>
              <em> Sixty-second Annual Meeting of the Association for Computational Linguistics (ACL)</em>, 2024 <br>
              <a href="https://arxiv.org/pdf/2404.04232">pdf</a>  / <a href="https://github.com/tqzhong/CG4MCTG">code</a>
              </div>
              <div id="tianqi" style="display:none">
              This paper proposes CompMCTG which serves as a benchmark encompassing diverse multi-aspect labeled datasets and a crafted three-dimensional evaluation protocol to holistically evaluate the compositional generalization of multi-aspect controllable text generation (MCTG) approaches, as well as Meta-MCTG that is a meta-learning inspired framework to mitigate the noticeable performance drop of  existing MCTG approaches in compositional generalization.
              </div><br>

              <div onmouseover="document.getElementById('smat').style.display = 'block';"
                onmouseout="document.getElementById('smat').style.display='none';">
                <papertitle>Unleashing the Power of Meta-tuning for Few-shot Generalization Through Sparse Interpolated Experts</papertitle></a><br>
                Shengzhuang Chen, <a href="https://jihoontack.github.io/">Jihoon Tack</a>, Yunqiao Yang, <a href="https://www.stats.ox.ac.uk/~teh/">Yee Whye Teh</a>, <a href="https://jonathan-schwarz.github.io/">Jonathan Richard Schwarz</a>,
                <i>Ying Wei*</i>
              <br>
              <em> Forty-first International Conference on Machine Learning (ICML)</em>, 2024 <br>
              <a href="https://arxiv.org/pdf/2403.08477">pdf</a>  / <a href="https://github.com/szc12153/sparse_meta_tuning">code</a>
              </div>
              <div id="smat" style="display:none">
              This paper addresses the so far limited success of meta-tuning on especially out-of-domain (OOD) tasks, where meta-tuning is a subsequent optimization stage for foundation models that attempts to harness the best of both parameter-efficient fine-tuning and meta-learning. The proposed approach Sparse MetA-Tuning (SMAT), trained to automatically isolate subsets of pre-trained parameters for meta-tuning on each task, successfully overcomes OOD sensitivity and delivers on the promise of enhancing the transfer abilities of vision foundation models beyond parameter-efficient fine-tuning. 
              </div><br>


              <div onmouseover="document.getElementById('metaformer').style.display = 'block';"
                onmouseout="document.getElementById('metaformer').style.display='none';">
                <papertitle>One Meta-tuned Transformer is What You Need for Few-shot Learning</papertitle></a><br>
                Xu Yang, <a href="https://www.huaxiuyao.io/">Huaxiu Yao</a>,  <i>Ying Wei*</i>
              <br>
              <em> Forty-first International Conference on Machine Learning (ICML)</em>, 2024 <br>
              <a href="https://openreview.net/pdf/06e74355729cbbba05e5627f2be61d331e35a2cb.pdf">pdf</a>  / <a href="https://github.com/xyang583/metaformer">code</a>
              </div>
              <div id="metaformer" style="display:none">
              This paper introduces MetaFormer, a new meta-tuning framework exclusively based on attention. MetaFormer enhances the few-shot learning capacity of vision transformers by integrating both sample and task relationships into the model, which includes Masked Sample Attention for embedding sample relationships and Patch-grained Task Attention for encapsulating task relationships. MetaFormer demonstrates coherence and compatibility with off-the-shelf pre-trained vision transformers and shows significant improvements in both inductive and transductive few-shot learning scenarios.
              </div><br>


              <div onmouseover="document.getElementById('pocl').style.display = 'block';"
                onmouseout="document.getElementById('pocl').style.display='none';">
                <papertitle>Mitigating Catastrophic Forgetting in Online Continual Learning by Modeling Previous Task Interrelations</papertitle></a><br>
                Yichen Wu, Hong Wang, <a href="https://peilinzhao.github.io/">Peilin Zhao</a>, <a href="https://sites.google.com/site/yefengzheng/">Yefeng Zheng</a>, <i>Ying Wei*</i>, <a href="https://sites.google.com/site/longkaihugo/home">Long-Kai Huang*</a>
              <br>
              <em> Forty-first International Conference on Machine Learning (ICML)</em>, 2024 <br>
              <a href="https://openreview.net/attachment?id=olbTrkWo1D&name=pdf">pdf</a> / code
              </div>
              <div id="pocl" style="display:none">
              This work reformulates replay-based continual learning methods as a unified framework, upon which we design a Pareto-Optimized CL algorithm (POCL) that leverages Pareto optimization to capture the interrelationship among previously learned tasks. POCL thus effectively enhances the overall performance of past tasks while ensuring the performance of the current task, further alleviating catastrophic forgetting.
              </div><br>

              <div onmouseover="document.getElementById('PKT-FCL').style.display = 'block';"
                onmouseout="document.getElementById('PKT-FCL').style.display='none';">
                <papertitle>Federated Continual Learning via Prompt-based Dual Knowledge Transfer</papertitle></a><br>
                Hongming Piao, Yichen Wu, <a href="https://www.cs.cityu.edu.hk/~dapengwu/">Dapeng Wu</a>, <i>Ying Wei*</i>
              <br>
              <em> Forty-first International Conference on Machine Learning (ICML)</em>, 2024 <br>
              <a href="https://openreview.net/pdf?id=Kqa5JakTjB">pdf</a>  / <a href="https://github.com/piaohongming/Powder">code</a>
              </div>
              <div id="PKT-FCL" style="display:none">
              This paper introduces the Prompt-based Knowledge Transfer FCL (PKT-FCL) algorithm that prompts positive knowledge transfer across tasks and clients, which has been overlooked before in federated continual learning. PKT-FCL not only reduces communication costs but also addresses privacy concerns through a novel approach for prompt generation and aggregation, showing superior performance in comprehensive experimental evaluations.
              </div><br>




            <div onmouseover="document.getElementById('mope-clip').style.display = 'block';"
                onmouseout="document.getElementById('mope-clip').style.display='none';">
                <papertitle>MoPE-CLIP: Structured Pruning for Efficient Vision-Language Models with Module-wise Pruning Error Metric</papertitle></a><br>
                Haokun Lin, <a href="https://haolibai.github.io/">Haoli Bai</a>, Zhili Liu, <a href="https://houlu369.github.io/">Lu Hou</a>, Muyi Sun, <a href="https://sites.google.com/site/aisquaredlab/">Linqi Song</a>,
                <i>Ying Wei*</i>, <a href="http://www.cbsr.ia.ac.cn/users/znsun/">Zhenan Sun*</a>
              <br>
              <em> IEEE / CVF Computer Vision and Pattern Recognition Conference (CVPR)</em>, 2024 <br>
              <a href="https://arxiv.org/abs/2403.07839">pdf</a>  / code 
              </div>
              <div id="mope-clip" style="display:none">
              This paper addresses the challenge of deploying large vision-language pre-trained models on platforms with limited computational resources by introducing a new metric, Module-wise Pruning Error (MoPE), which quantifies the impact of module removal on cross-modal task performance. Utilizing the MoPE metric, we propose a unified pruning framework that applies to both pre-training and fine-tuning stages, effectively compressing vision-language models while preserving their performance capabilities.
              </div><br>

              <div onmouseover="document.getElementById('vr-mcl').style.display = 'block';"
                onmouseout="document.getElementById('vr-mcl').style.display='none';">
                <papertitle>Meta Continual Learning Revisited: Implicitly Enhancing Online Hessian Approximation via Variance Reduction</papertitle></a><br>
                Yichen Wu, <a href="https://sites.google.com/site/longkaihugo/home">Long-Kai Huang</a>, Renzhen Wang, <a href="https://gr.xjtu.edu.cn/web/dymeng">Deyu Meng</a>, 
                <i>Ying Wei*</i>
              <br>
              <em>Twelfth International Conference on Learning Representations (ICLR)</em>, 2024 (<newsdate>Outstanding Honorable Mention / oral</newsdate>) <br>
              <a href="https://openreview.net/pdf?id=TpD2aG1h0D">pdf</a>  / <a href="https://github.com/WuYichen-97/Meta-Continual-Learning-Revisited-ICLR2024/tree/main">code</a>
              </div>
              <div id="vr-mcl" style="display:none">
              This study revisits Meta-Continual Learning (Meta-CL) and for the first time bridge Meta-CL with regularization-based methods. Concretely, Meta-CL implicitly approximates Hessian in an online manner, which enjoys the benefits of timely adaptation but meantime suffers from high variance induced by random memory buffer sampling. We are thus highly motivated to combine the best of both worlds, through the proposal of Variance Reduced Meta-CL (VR-MCL) to achieve both timely and accurate Hessian approximation. 
              </div><br>

              <div onmouseover="document.getElementById('ggf').style.display = 'block';"
                onmouseout="document.getElementById('ggf').style.display='none';">
                <papertitle>Gradual Domain Adaptation via Gradient Flow</papertitle></a><br>
                Zhan Zhuang, <a href="https://yuzhanghk.github.io/">Yu Zhang</a>, <i>Ying Wei*</i>
              <br>
              <em>Twelfth International Conference on Learning Representations (ICLR)</em>, 2024 (<newsdate>spotlight</newsdate>) <br>
              <a href="https://openreview.net/pdf?id=iTTZFKrlGV">pdf</a>  / <a href="https://github.com/zwebzone/ggf">code</a>
              </div>
              <div id="ggf" style="display:none">
              To address the challenge of ineffective intermediate domains for gradual domain adaptation (GDA), this work explores gradient flow to generate intermediate domains with preserving labels, thereby enabling us a fine-tuning method for GDA. We employ the Wasserstein gradient flow in Kullback–Leibler divergence to transport samples from the source to the target domain. To simulate the dynamics, we utilize the Langevin algorithm. Since the Langevin algorithm disregards label information and introduces diffusion noise, we introduce classifier-based and sample-based potentials to avoid label switching and dramatic deviations in the sampling process. 
              </div><br>


              <div onmouseover="document.getElementById('arp').style.display = 'block';"
                onmouseout="document.getElementById('arp').style.display='none';">
                <papertitle>Active Retrosynthetic Planning Aware of Route Quality</papertitle></a><br>
                <u>Luotian Yuan</u>, <u>Yemin Yu</u>, <i>Ying Wei*</i>, <a href="https://enkiwang.github.io/">Yongwei Wang</a>, Zhihua Wang, <a href="https://person.zju.edu.cn/en/wufei#751278">Fei Wu*</a>
              <br>
              <em>Twelfth International Conference on Learning Representations (ICLR)</em>, 2024<br>
              <a href="https://openreview.net/pdf?id=h7DGnWGeos">pdf</a>  / code
              </div>
              <div id="arp" style="display:none">
              This study addresses the long-standing challenge of route quality evaluation in retrosynthetic planning, through an Active Retrosynthetic Planning (ARP) framework that involves a minimum annotation from chemists. The proposed ARP remains compatible with established retrosynthetic planners, which trains an actor that decides whether to query the quality of a reaction and resorts to a critic to estimate the value of a molecule with its preceding reaction quality as input. On both the benchmark and an expert dataset, ARP outperforms the existing state-of-the-art approach by 6.2% in route quality while reducing the query cost by 12.8%.
              </div><br>


              <div onmouseover="document.getElementById('retroood').style.display = 'block';"
                onmouseout="document.getElementById('retroood').style.display='none';">
                <papertitle>RetroOOD: Understanding Out-of-Distribution Generalization in Retrosynthesis Prediction</papertitle></a><br>
                <u>Yemin Yu</u>, <u>Luotian Yuan</u>, <i>Ying Wei*</i>, <a href="https://hanyugao.com/">Hanyu Gao</a>, Xinhai Ye, Zhihua Wang, <a href="https://person.zju.edu.cn/en/wufei#751278">Fei Wu</a>
              <br>
              <em>Thirty-eighth Annual AAAI Conference on Artificial Intelligence (AAAI)</em>, 2024<br>
              <a href="https://arxiv.org/pdf/2312.10900.pdf">pdf</a>  / code
              </div>
              <div id="retroood" style="display:none">
              Despite steady progress of existing retrosynthesis methods on standard benchmarks, our understanding of  them under the premise of distribution shifts remains stagnant. This study fills in the gap by (1) formally sorting out two types of distribution shifts in retrosynthesis prediction, (2) constructing two groups of benchmark datasets, (3) conducting comprehensive experiments to reveal the limitations of previous in-distribution evaluation and state-of-the-art methods. and (4) proposing two model-agnostic techniques that can improve the OOD generalization of arbitrary off-the-shelf retrosynthesis prediction algorithms.
              </div><br>



              <div onmouseover="document.getElementById('hprompt_cpt').style.display = 'block';"
                onmouseout="document.getElementById('hprompt_cpt').style.display='none';">
                <papertitle>Towards Anytime Fine-tuning: Continually Pre-trained Language Models with Hypernetwork Prompts</papertitle></a><br>
                Gangwei Jiang, Caigao Jiang, Siqiao Xue, James Y. Zhang, Jun Zhou, <a href="http://staff.ustc.edu.cn/~liandefu/">Defu Lian*</a>, 
                <i>Ying Wei*</i>
              <br>
              <em>2023 Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>, 2023<br>
              <a href="pubs/HPrompt_CPT_EMNLP2023.pdf">pdf</a> 
              </div>
              <div id="hprompt_cpt" style="display:none">
              This study first investigates "anytime fine-tuning" effectiveness of existing continual learning approaches, concluding with unanimously decreased performance on unseen domains. To this end, we propose a prompt-guided continual pre-training method, where we train a hypernetwork to generate domain-specific prompts by both agreement and disagreement losses. Our method achieves improvements of 3.57% and 3.4% on two real-world datasets (including domain shift and temporal shift), respectively.
              </div><br>


              <div onmouseover="document.getElementById('ebml').style.display = 'block';"
                onmouseout="document.getElementById('ebml').style.display='none';">
                <papertitle>Secure Out-of-Distribution Task Generalization with Energy-Based Models</papertitle></a><br>
                Shengzhuang Chen,
                <a href="https://sites.google.com/site/longkaihugo/home">Long-Kai Huang</a>,
                <a href="https://jonathan-schwarz.github.io/">Jonathan Richard Schwarz</a>,
                <a href="https://yilundu.github.io/">Yilun Du</a>,
                <i>Ying Wei*</i>
              <br>
              <em>Thirty-seventh Conference on Neural Information Processing Systems (NeurIPS)</em>, 2023<br>
              <a href="pubs/EBML_NeurIPS2023.pdf">pdf</a>  / <a href="https://github.com/NTU-LANTERN/EBML.git">code</a>
              </div>
              <div id="ebml" style="display:none">
              In this work, we propose a single coherent framework named Energy-Based Meta-Learning (EBML) that supports both detection and adaptation of OOD tasks, while remaining compatible with off-the-shelf meta-learning backbones. EBML learns to characterize any arbitrary meta-training task distribution with the composition of two expressive neural-network-based energy functions. We deploy the sum of the two energy functions, being proportional to the joint distribution of a task, as a reliable score for detecting OOD tasks; during meta-testing, we adapt the OOD task to in-distribution tasks by energy minimization.
              </div><br>


               <div onmouseover="document.getElementById('comp_bench').style.display = 'block';"
                onmouseout="document.getElementById('comp_bench').style.display='none';">
                <papertitle>Does Continual Learning Meet Compositionality? New Benchmarks and An Evaluation Framework</papertitle></a><br>
                Weiduo Liao,
                <i>Ying Wei*</i>,
                Mingchen Jiang, 
                <a href="https://www.cs.cityu.edu.hk/~qzhan7/index.html">Qingfu Zhang*</a>,
                <a href="https://cse.sustech.edu.cn/faculty/~hisao/">Hisao Ishibuchi*</a>
              <br>
              <em>Thirty-seventh Conference on Neural Information Processing Systems (NeurIPS)</em>, 2023<br>
              <em>Track on Datasets and Benchmarks</em><br>
              <a href="https://openreview.net/pdf?id=38bZuqQOhC">pdf</a> / <a href="https://github.com/NTU-LANTERN/CFST.git">code</a>
              </div>
              <div id="comp_bench" style="display:none">
             We present two vision benchmarks, namely Compositional GQA (CGQA) and Compositional OBJects365 (COBJ), along with a novel evaluation framework called Compositional Few-Shot Testing (CFST). Comprehensive empirical results on systematicity, productivity, and substitutivity aspects of compositional generalization demonstrate that current continual learning techniques do exhibit somewhat favorable compositionality in their learned feature extractors, while future research on modularity is urgently needed.
              </div><br>


             <div onmouseover="document.getElementById('concept_tuning').style.display = 'block';"
                onmouseout="document.getElementById('concept_tuning').style.display='none';">
                <papertitle>Concept-wise Fine-tuning Matters in Preventing Negative Transfer</papertitle></a><br>
                Yunqiao Yang,
                <a href="https://sites.google.com/site/longkaihugo/home">Long-Kai Huang</a>,
                <i>Ying Wei*</i>
              <br>
              <em>IEEE/CVF International Conference on Computer Vision (ICCV)</em>, 2023<br>
              <a href="pubs/ConceptTuning_ICCV2023.pdf">pdf</a> / <a href="https://github.com/NTU-LANTERN/Concept-wise_Fine-tuning.git">code</a>
              </div>
              <div id="concept_tuning" style="display:none">
              We propose a Concept-wise fine-Tuning (Concept-Tuning) approach which refines feature representations in the level of patches with each patch encoding a concept. Concept-Tuning minimizes the negative impacts of rare features and spuriously correlated features in a pre-trained model by (1) maximizing the mutual information between examples in the same category with regard to a slice of rare features (a patch) and (2) applying front-door adjustment via attention neural networks in channels and feature slices (patches).
              </div><br>


             <div onmouseover="document.getElementById('spansub').style.display = 'block';"
                onmouseout="document.getElementById('spansub').style.display='none';">
                <papertitle>Learning to Substitute Spans towards Improving Compositional Generalization</papertitle></a><br>
                Zhaoyi Li,
                <i>Ying Wei*</i>,
                <a href="http://staff.ustc.edu.cn/~liandefu/">Defu Lian*</a>
              <br>
              <em>Sixty-first Annual Meeting of the Association for Computational Linguistics (ACL)</em>, 2023 (<newsdate>oral</newsdate>)<br>
              <a href="https://aclanthology.org/2023.acl-long.157.pdf">pdf</a> / <a href="https://github.com/NTU-LANTERN/Compgen_l2s2.git">code</a>
              </div>
              </div>
              <div id="spansub" style="display:none">
                This work introduces a compositional data augmentation approach that incurs additional compositional inductive biasto pre-trained models. We first propose a novel compositional augmentation strategy dubbed Span Substitution (SpanSub) that enables <em>multi-grained</em> composition of substantial substructures in the whole training set. Over and above that, we introduce the Learning to Substitute Span (L2S2) framework which empowers the learning of span substitution probabilities in SpanSub in an end-to-end manner by maximizing the loss of neural sequence models, so as to <em>outweigh those challenging compositions</em> with elusive concepts and novel surroundings
              </div><br>

               <div onmouseover="document.getElementById('biqa').style.display = 'block';"
                onmouseout="document.getElementById('biqa').style.display='none';">
                <papertitle>Blind Image Quality Assessment via Vision-Language Correspondence: A Multitask Learning Perspective</papertitle></a><br>
                <a href="https://sites.google.com/view/r-panda/home">Weixia Zhang,</a>
                 Guangtao Zhai, 
                <i>Ying Wei</i>,
                Xiaokang Yang, 
                <a href="https://kedema.org/">Kede Ma</a>
              <br>
              <em>IEEE / CVF Computer Vision and Pattern Recognition Conference (CVPR)</em>, 2023<br>
              <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_Blind_Image_Quality_Assessment_via_Vision-Language_Correspondence_A_Multitask_Learning_CVPR_2023_paper.pdf">pdf</a> 
              </div>
              <div id="biqa" style="display:none">
               We develop a general and automated multitask learning scheme for blind image quality assessment to exploit auxiliary knowledge from other tasks, in a way that the model parameter sharing and the loss weighting are determined automatically. Specifically, we first describe all candidate label combinations (from multiple tasks) using a textual template, and compute the joint probability from the cosine similarities of the visual-textual embeddings in CLIP. Predictions of each task can be inferred from the joint distribution, and optimized by carefully designed loss functions.
              </div><br>



               <div onmouseover="document.getElementById('pmsr').style.display = 'block';"
                onmouseout="document.getElementById('pmsr').style.display='none';">
                <papertitle>Learning Chemical Rules of Retrosynthesis with Pre-training</papertitle></a><br>
                Yinjie Jiang,
                <i>Ying Wei*</i>,
                <a href="https://person.zju.edu.cn/en/wufei#751278">Fei Wu*</a>,
                <a href="https://person.zju.edu.cn/en/hzx">Zhengxing Huang</a>,
                <a href="https://kunkuang.github.io/">Kun Kuang</a>,
                Zhihua Wang
              <br>
              <em>Thirty-Seventh AAAI Conference on Artificial Intelligence (AAAI)</em>, 2023 <br>
              <a href="pubs/PMSR_AAAI2023.pdf">pdf</a> 
              </div>
              <div id="pmsr" style="display:none">
              Towards the very burgeoning research area of AI-aided retrosythesis, we propose a pre-training solution to address the pronounced remaining issue regarding template-free methods, i.e., failing to conform to chemical rules. Concretely, we enforce the atom conservation rule via a molecule reconstruction pre-training task, and the reaction rule that dictates reaction centers via a reaction type guided contrastive pre-training task. Our empirical results show that the pre-training solution significantly boosts the single-step retrosynthesis accuracies.
              </div><br>


              <div onmouseover="document.getElementById('atu').style.display = 'block';"
                onmouseout="document.getElementById('atu').style.display='none';">
                <papertitle>Adversarial Task Up-sampling for Meta-learning</papertitle></a><br>
              Yichen Wu,
              <a href="https://sites.google.com/site/longkaihugo/home">Long-Kai Huang*</a>,
              <i>Ying Wei*</i>


              <br>
              <em>36th Conference on Neural Information Processing Systems (NeurIPS)</em>, 2022 (<newsdate>spotlight</newsdate>) <br>
              <a href="pubs/ATU_NeurIPS2022.pdf">pdf</a> / <a href="https://github.com/NTU-LANTERN/Adversarial_Task_Up-sampling_for_Meta-learning">code</a>
              </div>
              <div id="atu" style="display:none">
              This work named Adversarial Task Up-sampling (ATU) pushes ahead augmentation of sufficiently imaginary meta-training tasks with task-correctness guarantee, where we seek an approach that up-samples meta-training tasks from the task manifold via a task up-sampling network. ATU also suffices to generate tasks that can maximally contribute to the latest meta-learner by maximizing an adversarial loss. 
              </div><br>


              <div onmouseover="document.getElementById('vrm').style.display = 'block';"
                onmouseout="document.getElementById('vrm').style.display='none';">
                <papertitle>Improving Task-Specific Generalization in Few-Shot Learning via Adaptive Vicinal Risk Minimization</papertitle></a><br>
              <a href="https://sites.google.com/site/longkaihugo/home">Long-Kai Huang</a>,
              <i>Ying Wei*</i>


              <br>
              <em>36th Conference on Neural Information Processing Systems (NeurIPS)</em>, 2022 (<newsdate>spotlight</newsdate>)<br>
              <a href="pubs/VRM_NeurIPS2022.pdf">pdf</a> 
              </div>
              <div id="vrm" style="display:none">
              This work focuses on improving task-specific generalization in the meta-testing stage, where we derive the vicinal loss function that approximates the true task distribution with aggregation of per-sample Gaussian-like vicinal distributions. We estimate the statistical parameters of the vicinal distribution for each training sample by 1) initiating a random walk from the sample and 2) computing the weighted mean and variance of those unlabeled data passed by the walk. The proposed method outperforms state-of-the-art few-shot learning baselines in four benchmarks.
              </div><br>


              <div onmouseover="document.getElementById('grasp').style.display = 'block';"
                onmouseout="document.getElementById('grasp').style.display='none';">
                <papertitle>GRASP: Navigating Retrosynthetic Planning with Goal-driven Policy</papertitle></a><br>
              Yemin Yu,
              <i>Ying Wei*</i>,
              <a href="https://kunkuang.github.io/">Kun Kuang</a>,
              <a href="https://person.zju.edu.cn/en/hzx">Zhengxing Huang</a>,
              <a href="https://huaxiuyao.mystrikingly.com/">Huaxiu Yao</a>,
              <a href="https://person.zju.edu.cn/en/wufei#751278">Fei Wu*</a>


              <br>
              <em>36th Conference on Neural Information Processing Systems (NeurIPS)</em>, 2022 <br>
              <a href="pubs/GRASP_NeurIPS2022.pdf">pdf</a>  / <a href="https://github.com/NTU-LANTERN/GRASP_retro">code</a>
              </div>
              <div id="grasp" style="display:none">
              Retrosynthetic planning occupies a crucial position in synthetic chemistry and, accordingly, drug discovery, which aims to find synthetic pathways of a target molecule through a sequential decision-making process on a set of feasible reactions. This work named Goal-dRiven Actor-critic retroSynthetic Planning (GRASP) framework first (1) formulates the retrosynthetic planning into a reinforcement learning framework which enjoys more efficient and accurate value estimation of a molecule, and (2) achieves goal-driven retrosynthesis navigation toward a user-demand objective. 
              </div><br>


            <div onmouseover="document.getElementById('transrate').style.display = 'block';"
                onmouseout="document.getElementById('transrate').style.display='none';">
                <papertitle>Frustratingly Easy Transferability Estimation</papertitle></a><br>
              <a href="https://sites.google.com/site/longkaihugo/home">Long-Kai Huang</a>,
              <a href="https://ranger.uta.edu/~huang/">Junzhou Huang</a>,
              <a href="http://www.cs.ust.hk/~qyang/">Qiang Yang</a>,
              <i>Ying Wei*</i>


              <br>
              <em>39th International Conference on Machine Learning (ICML)</em>, 2022 <br>
              <a href="https://arxiv.org/pdf/2106.09362.pdf">pdf</a> / <a href="https://github.com/Long-Kai/TransRate.git">code</a>
              </div>
              </div>
              <div id="transrate" style="display:none">
              We propose a simple (10 lines of codes), efficient (through a single pass over examples of a target task), yet effective (on 26 pre-trained models and 16 downstream tasks) transferability measure named TransRate for fine-tuning pre-trained models. TransRate measures the mutual information between features of target examples by a pre-trained model and labels of them, which we estimate using coding rate.
              </div><br>

            <div onmouseover="document.getElementById('causal').style.display = 'block';"
                onmouseout="document.getElementById('causal').style.display='none';">
                <papertitle>The Role of Deconfounding in Meta-learning</papertitle></a><br>
              <u>Yinjie Jiang</u>,
              <u>Zhengyu Chen</u>,
              <a href="https://kunkuang.github.io/">Kun Kuang*</a>, Luotian Yuan, Xinhai Ye, Zhihua Wang,
              <a href="https://person.zju.edu.cn/en/wufei#751278">Fei Wu*</a>,
              <i>Ying Wei*</i>

              <br>
              <em>39th International Conference on Machine Learning (ICML)</em>, 2022 <br>
              <a href="https://proceedings.mlr.press/v162/jiang22a/jiang22a.pdf">pdf</a>
              </div>
              <div id="causal" style="display:none">
              This work offers a novel causal perspective of meta-learning, through which we explain the memorization effect as a confounder and frame previous anti-memorization methods as  different deconfounder approaches. Derived from the causal inference principle of front-door adjustment, we propose two frustratingly easy but effective deconfounder algorithms.
              </div><br>


            <div onmouseover="document.getElementById('retro_survey').style.display = 'block';"
                onmouseout="document.getElementById('retro_survey').style.display='none';">
                <papertitle>Artificial Intelligence for Retrosynthesis Prediction</papertitle></a><br>
              <u>Yinjie Jiang</u>,
              <u>Yemin Yu</u>,
              <u>Ming Kong</u>, Yu Mei, Luotian Yuan, Zhengxing Huang,
              <a href="https://kunkuang.github.io/">Kun Kuang</a>, Zhihua Wang, 
              <a href="https://huaxiuyao.mystrikingly.com/">Huaxiu Yao</a>,
              <a href="https://sites.google.com/site/jamesyzou/">James Zou</a>,
              <a href="https://cheme.mit.edu/profile/connor-w-coley/">Connor W. Coley</a>,
              <i>Ying Wei*</i>

              <br>
              <em>Engineering</em>, 2022<br>
              <a href="https://reader.elsevier.com/reader/sd/pii/S2095809922005665?token=0883EE55C7B9040EC2FA7796B14B5D5D4BC98DE268C89277A42051EA8E9B1324123FFF15E0FF1CF812525FE90A3F4027&originRegion=us-east-1&originCreation=20230130141648">pdf</a>
              </div>
              <div id="retro_survey" style="display:none">
              In recent years, there has been a dramatic rise in interest in retrosynthesis prediction with AI techniques. This survey describes the current landscape of AI-driven retrosynthesis prediction, including (1) formal definitions of the retrosynthesis problem, (2) the outstanding research challenges therein, (3) related AI techniques and recent progress that enable retrosynthesis prediction, (4) a novel landscape that provides a comprehensive categorization of different retrosynthesis prediction components, (5) how AI reshapes each component, and (6) promising areas for future research.
              </div><br>


              <div onmouseover="document.getElementById('sshtc').style.display = 'block';"
                onmouseout="document.getElementById('sshtc').style.display='none';">
                <papertitle>Disentangling Task Relations for Few-shot Text Classification via Self-Supervised Hierarchical Task Clustering</papertitle></a><br>
              Juan Zha,
              <a href="https://hsqmlzno1.github.io/">Zheng Li</a>,
              <i>Ying Wei</i>,
              <a href="https://yuzhanghk.github.io/">Yu Zhang</a>


              <br>
              <em>2022 Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>, 2022 <br>
              <a href="https://arxiv.org/pdf/2211.08588.pdf">pdf</a>
              </div>
              <div id="sshtc" style="display:none">
              This work named self-supervised hierarchical task cluster (SS-HTC) improves few-shot text classification. SS-HTC  customizes cluster-specific knowledge by dynamically organizing heterogeneous tasks into different clusters in hierarchical levels and also disentangles underlying relations between tasks to improve the interpretability. Extensive experiments on five public FSTC benchmark datasets demonstrate the effectiveness of SS-HTC.
              </div><br>


            <div onmouseover="document.getElementById('ste').style.display = 'block';"
                onmouseout="document.getElementById('ste').style.display='none';">
                <papertitle>Self-supervised Text Erasing with Controllable Image Synthesis</papertitle></a><br>
              Gangwei Jiang,
              Shiyao Wang, 
              Tiezheng Ge,
              Yuning Jiang,
              <i>Ying Wei</i>,
              <a href="http://staff.ustc.edu.cn/~liandefu/">Defu Lian</a>

              <br>
              <em>30th ACM International Conference on Multimedia (MM)</em>, 2022 <br>
              <a href="https://arxiv.org/pdf/2204.12743.pdf">pdf</a>
              </div>
              <div id="ste" style="display:none">
              This work studies a novel self-supervised text erasing framework to alleviate the heavy reliance on costly annotations. Specifically, we propose a style-aware image synthesis function that generates synthetic images with diverse style texts and a policy network that controls the synthetic mechanisms to bridge the text style gap between synthetic and real-world data. We have also constructed a new dataset called PosterErase.
              </div><br>

            <div onmouseover="document.getElementById('ats').style.display = 'block';"
                onmouseout="document.getElementById('ats').style.display='none';">
                <papertitle>Meta-learning with an Adaptive Task Scheduler</papertitle></a><br>
              <a href="https://huaxiuyao.mystrikingly.com/"><u>Huaxiu Yao</u></a>,
              <u>Yu Wang</u>,
              <i>Ying Wei*</i>, 
              <a href="http://peilinzhao.weebly.com/">
              Peilin Zhao</a>,  
              <a href="http://www.cse.psu.edu/~mzm616/">Mehrdad Mahdavi</a>,  
              <a href="http://staff.ustc.edu.cn/~liandefu/">Defu Lian</a>,  
              <a href="https://ai.stanford.edu/~cbfinn/">Chelsea Finn</a>



              <br>
              <em>35th Conference on Neural Information Processing Systems (NeurIPS)</em>, 2021 <br>
              <a href="https://proceedings.neurips.cc/paper/2021/file/3dc4876f3f08201c7c76cb71fa1da439-Paper.pdf">pdf</a>  /
              <a href="https://github.com/huaxiuyao/ATS">code</a> 
              </div>
              <div id="ats" style="display:none">
              This work pursues an adaptive task scheduler for meta-learning tasks that are likely detrimental with noise or imbalanced given a limited number of meta-training tasks. We for the first time design a neural scheduler to decide which meta-training tasks to use next and train the scheduler to optimize the generalization capacity of the meta-knowledge to unseen tasks. We have shown that such a scheduler theoretically improves the optimization landscape and empirically outshines conventional schedulers (including the commonly adopted random sampling).
              </div><br>

            <div onmouseover="document.getElementById('frml').style.display = 'block';"
                onmouseout="document.getElementById('frml').style.display='none';">
                <papertitle>Functionally Regionalized Knowledge Transfer for Low-resource Drug Discovery</papertitle></a><br>
              <a href="https://huaxiuyao.mystrikingly.com/">Huaxiu Yao</a>,
              <i>Ying Wei*</i>, 
              <a href="https://sites.google.com/site/longkaihugo/home">Long-Kai Huang</a>, 
              Ding Xue,
              <a href="https://ranger.uta.edu/~huang/">Junzhou Huang</a>,
              <a href="https://faculty.ist.psu.edu/jessieli/Site/index.html">Zhenhui Li</a>


              <br>
              <em>35th Conference on Neural Information Processing Systems (NeurIPS)</em>, 2021 <br>
              <a href="https://papers.nips.cc/paper/2021/file/459a4ddcb586f24efd9395aa7662bc7c-Paper.pdf">pdf</a> 
              </div>
              <div id="frml" style="display:none">
              This paper seeks to remedy the lack of labeled compounds with activities (ADMET properties) in virtual screening (lead optimization) of drug by transferring the knowledge from previous assays, namely in-vivo experiments, collected by different laboratories and against various target proteins. We propose a functionally regionalized meta-learning algorithm, with the architectural compositional capability, to accommodate wildly different assays and meantime capture the relationship between assays. 


              </div><br>

              <div onmouseover="document.getElementById('metats').style.display = 'block';"
                onmouseout="document.getElementById('metats').style.display='none';">
                <papertitle>MetaTS: Meta Teacher-Student Network for Multilingual SequenceLabeling with Minimal Supervision</papertitle></a><br>
              <a href="https://hsqmlzno1.github.io/">Zheng Li</a>,
              <a href="https://danqingz.github.io/">Danqing Zhang</a>,
              Tianyu Cao,
              <i>Ying Wei</i>, 
              Yiwei Song,
              Bing Yin


              <br>
              <em>2021 Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>, 2021 <br>
              <a href="https://aclanthology.org/2021.emnlp-main.255.pdf">pdf</a> 
              </div>
              <div id="metats" style="display:none">
              We explore multilingual sequence labeling with a single unified model for multiple languages and minimal supervision. Specifically, we resort to the teacher-student framework to leverage large multilingual unlabeled data. We propose a meta teacher-student (MetaTS) network that allows the teacher to dynamically adapt its pseudo-annotation strategies by the student's feedback on the generated pseudo-labeled data of each language.

              </div><br>

            <div onmouseover="document.getElementById('tnp_icml').style.display = 'block';"
                onmouseout="document.getElementById('tnp_icml').style.display='none';">
                <papertitle>Meta-learning Hyperparameter Performance Prediction with Neural Processes</papertitle></a><br>
              <i>Ying Wei</i>, 
              <a href="http://peilinzhao.weebly.com/">Peilin Zhao</a>,  
              <a href="https://ranger.uta.edu/~huang/">Junzhou Huang</a>


              <br>
              <em>38th International Conference on Machine Learning (ICML)</em>, 2021 <br>
              <a href="http://proceedings.mlr.press/v139/wei21c/wei21c.pdf">pdf</a> / 
              <a href="https://github.com/judyweiying/TNP/">code</a>
              </div>
              <div id="tnp_icml" style="display:none">
              We transfer knowledge from historical hyperparameter optimization (HPO) trials on other datasets to speed up HPO of a huge dataset where even a single trial is costly. The proposed meta-learning algorithm first introduces neural processes (NPs) as a surrogate model which empowers the simultaneous transfer of trial observations, parameters of NPs, and initial hyperparameter configurations.
              </div><br>

          <!--<heading2><i>Preprints</i></heading2><br><br>-->
          <div onmouseover="document.getElementById('metamix').style.display = 'block';"
                onmouseout="document.getElementById('metamix').style.display='none';">
                <papertitle>Improving Generalization in Meta-learning via Task Augmentation</papertitle></a><br>
              <a href="https://huaxiuyao.mystrikingly.com/"><u>Huaxiu Yao</u></a>, 
              <a href="https://sites.google.com/site/longkaihugo/home"><u>Long-Kai Huang</u></a>, 
              <a href="https://linjunz.github.io/">Linjun Zhang</a>,  <i>Ying Wei*</i>, Li Tian,
              <a href="https://www.james-zou.com/">James Zou</a>,  
              <a href="https://ranger.uta.edu/~huang/">Junzhou Huang</a>,
              <a href="https://faculty.ist.psu.edu/jessieli/Site/index.html">Zhenhui Li</a>               


              <br>
              <em>38th International Conference on Machine Learning (ICML)</em>, 2021 <br>
              <a href="http://proceedings.mlr.press/v139/yao21b/yao21b.pdf">pdf</a> / 
              <a href="https://arxiv.org/pdf/2007.13040.pdf">arXiv</a> /
              <a href="https://github.com/huaxiuyao/MetaMix">code</a>
              </div>
              <div id="metamix" style="display:none">
              This work addresses the meta-overfitting problem. We solve the problem by augmenting as many tasks as possible. Concretely, we propose the two criteria for valid task augmentation and also two task augmentation methods that satisfy the criteria. Theoretical studies and empirical results both demonstrate that the proposed task augmentation strategies significantly mitigate the meta-overfitting. Also, the task augmentation strategies remain compatible with any advanced meta-learning algorithms.
              </div><br>




        <div onmouseover="document.getElementById('mgl').style.display = 'block';"
                onmouseout="document.getElementById('mgl').style.display='none';">
                <papertitle>Learn to Cross-lingual Transfer with Meta Graph Learning Across Heterogeneous Languages</papertitle></a><br>
              <a href="https://hsqmlzno1.github.io/">Zheng Li</a>, Mukul Kumar, William Headden, Bing Yin, <i>Ying Wei</i>, 
              <a href="https://yuzhanghk.github.io/">Yu Zhang</a>,  
              <a href="http://www.cs.ust.hk/~qyang/">Qiang Yang</a>              
              <br>
              <em>2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>, 2020 <br>
              <a href="https://www.aclweb.org/anthology/2020.emnlp-main.179.pdf">pdf</a>
              <!--<a href="https://arxiv.org/abs/1909.03209">arXiv</a>-->
              </div>
              <div id="mgl" style="display:none">
              This work focuses on the problem of cross-lingual transfer (CLT). For each CLT task, we formulate the transfer process as information propagation over a dynamic graph. More importantly, we improve the transfer effectiveness by extracting meta-knowledge such as propagation strategies from previous CLT experiences. 
              </div><br>


        <div onmouseover="document.getElementById('grover').style.display = 'block';"
                onmouseout="document.getElementById('grover').style.display='none';">
                <papertitle>Self-Supervised Graph Transformer on Large-Scale Molecular Data</papertitle></a><br>
               <u>Yu Rong</u>, 
              <a href="http://yataobian.com/"><u>Yatao Bian</u></a>,  Tingyang Xu, Weiyang Xie, <i>Ying Wei</i>,
              <a href="https://sites.google.com/site/wenbinghuangshomepage/home">Wenbing Huang</a>,  
              <a href="http://ranger.uta.edu/~huang/">Junzhou Huang</a>              
              <br>
              <em>34th Annual Conference on Neural Information Processing Systems (NeurIPS)</em>, 2020 <br> 
              <a href="https://papers.nips.cc/paper/2020/file/94aef38441efa3380a3bed3faf1f9d5d-Paper.pdf">pdf</a>             
              <!--<a href="https://arxiv.org/abs/1909.03209">arXiv</a>-->
              </div>
              <div id="grover" style="display:none">
              We propose a novel framework, GROVER, for effective molecular representation which is a crucial prerequisite in AI-driven drug design and discovery. GROVER learns to characterize molecules with rich and semantic features from enormous unlabeled molecular data, with carefully designed self-supervised tasks in node-, edge-, and graph-level. Besides, GROVER itself is more expressive, integrating Message Passing Networks into the Transformer-style architecture.
              </div><br>

      <div onmouseover="document.getElementById('ast').style.display = 'block';"
                onmouseout="document.getElementById('ast').style.display='none';">
                <papertitle>Adversarial Sparse Transformer for Time Series Forecasting</papertitle></a><br>
                <u>Sifan Wu</u>,  Xi Xiao, <u>Qianggang Ding</u>, <a href="http://peilinzhao.weebly.com/">Peilin Zhao</a>,
                <i>Ying Wei</i>, <a href="http://ranger.uta.edu/~huang/">Junzhou Huang</a>              
              <br>
              <em>34th Annual Conference on Neural Information Processing Systems (NeurIPS)</em>, 2020 <br>
              <a href="https://papers.nips.cc/paper/2020/file/c6b8c8d762da15fa8dbbdfb6baf9e260-Paper.pdf">pdf</a>
              <!--<a href="https://arxiv.org/abs/1909.03209">arXiv</a>-->
              </div>
              <div id="ast" style="display:none">
              Existing time series forecasting methods fail to either capture stochasticity of data or forecast for a long time horizon due to error accumulation. In this work, we are motivated to address the two issues with a novel time series forecasting model. The model, Adversarial Sparse Transformer (AST), based on GAN, adopts a sparse Transformer as the generator to learn a sparse attention map for forecasting and meanwhile takes a discriminator to improve the prediction performance at a sequence level.
              </div><br>

 			<div onmouseover="document.getElementById('couda').style.display = 'block';"
                onmouseout="document.getElementById('couda').style.display='none';">
                <papertitle>Collaborative Unsupervised Domain Adaptation for Medical Image Diagnosis</papertitle></a><br>
              <a href="https://sites.google.com/view/yifan-zhang/%E9%A6%96%E9%A1%B5"><u>Yifan Zhang</u></a>,
        <i><u>Ying Wei</u></i>, <u>Qingyao Wu</u>, 
              <a href="http://peilinzhao.weebly.com/">Peilin Zhao</a>,  Shuaicheng Niu, 
              <a href="http://www.tanmingkui.com/">Mingkui Tan</a>,  
              <a href="http://ranger.uta.edu/~huang/">Junzhou Huang</a>              
              <br>
              <em>IEEE Transactions on Image Processing</em>, 2020 <br>   
              <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9142394">pdf</a>
              <!--<a href="https://arxiv.org/abs/1909.03209">arXiv</a>-->
              </div>
              <div id="couda" style="display:none">
              We are strongly motivated to improve unsupervised domain adaptation for medical image diagnosis, from the perspectives of denoising noisy annotations due to limited expertise and differentiating the adaptation difficulty of images that have significant discrepancies. The proposed, harnessing the collective intelligence of two peer networks, achieves the goals via a noise co-adaptation layer and a transferability-aware weight for each image.
              </div><br>

			  <div onmouseover="document.getElementById('translider').style.display = 'block';"
                onmouseout="document.getElementById('translider').style.display='none';">
                <papertitle>TranSlider: Transfer Ensemble Learning from Exploitation to Exploration</papertitle></a><br>
              <u>Kuo Zhong</u>,
        <i><u>Ying Wei*</u></i>, 
              <a href="https://www-en.sz.tsinghua.edu.cn/INFORMATIONSCIENCE/108547.jhtml">Chun Yuan</a>,  
              Haoli Bai,
              <a href="http://ranger.uta.edu/~huang/">Junzhou Huang</a>              
              <br>
              <em>Twenty-sixth ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD)</em>, 2020 <br> 
              <a href="https://dl.acm.org/doi/pdf/10.1145/3394486.3403079">pdf</a>                
              <!--<a href="https://arxiv.org/abs/1909.03209">arXiv</a>-->
              </div>
              <div id="translider" style="display:none">
              Learning a strategy dictating what and where to transfer is key to avoid negative transfer, while the strategy always suffers from overfitting in light of limited annotations in a target domain. For the first time, we propose transfer ensemble learning to solve the problem. We propose to generate a spectrum of models in decreasing transferability, ranging from pure exploitation of the source model to unconstrained exploration for the target domain.
              </div><br>

              <div onmouseover="document.getElementById('grl').style.display = 'block';"
                onmouseout="document.getElementById('grl').style.display='none';">
                <papertitle>Graph Few-shot Learning via Knowledge Transfer</papertitle></a><br>
              <a href="http://huaxiuyao.mystrikingly.com/">Huaxiu Yao</a>,
              <a href="https://chuxuzhang.github.io/">Chuxu Zhang</a>,
        <i>Ying Wei*</i>,
              <a href="http://www.meng-jiang.com/">Meng Jiang</a>, 
              <a href="https://suhangwang.ist.psu.edu/">Suhang Wang</a>, 
              <a href="http://ranger.uta.edu/~huang/">Junzhou Huang</a>,
              <a href="https://www3.nd.edu/~nchawla/">Nitesh Chawla</a>,
              <a href="https://faculty.ist.psu.edu/jessieli/Site/index.html">Zhenhui Li</a>               
              <br>
              <em>Thirty-Fourth AAAI Conference on Artificial Intelligence (AAAI)</em>, 2020 <br>     
              <a href="https://arxiv.org/pdf/1910.03053.pdf">pdf</a>                    
              <!--<a href="https://arxiv.org/abs/1909.03209">arXiv</a>-->
              </div>
              <div id="grl" style="display:none">
              For the first time, we attack the problem of semi-supervised node classification by transferring the knowledge learned from historical graphs. We propose a novel meta-learning algorithm on graphs instead of i.i.d. data. We learn a transferable metric space for node similarity, where two embedding functions encrypting both local and global structures are learned from previous graphs.
              </div><br>



              <div onmouseover="document.getElementById('tnp').style.display = 'block';"
                onmouseout="document.getElementById('tnp').style.display='none';">
              <a href="https://arxiv.org/pdf/1909.03209.pdf">
                <papertitle>Transferable Neural Processes for Hyperparameter Optimization</papertitle></a><br>
			  <i>Ying Wei</i>,
              <a href="http://peilinzhao.weebly.com/">Peilin Zhao</a>, 
              <a href="http://huaxiuyao.mystrikingly.com/">Huaxiu Yao</a>,
              <a href="http://ranger.uta.edu/~huang/">Junzhou Huang</a>
              <br>
              <em>The Meta Learning Workshop at NeurIPS</em>, 2019 <br>              
              <a href="https://arxiv.org/abs/1909.03209">arXiv</a>  
              </div>
              <div id="tnp" style="display:none">
              Conventional hyperparameter optimization (HPO) algorithms require considerable hyperparameter evaluation trials,  which impedes their success in wider applications where a single trial on a huge dataset is often costly. Thereon, we are inspired to speed up HPO by transferring knowledge from historical HPO trials on other datasets. The proposed meta-learning algorithm innovates the dataset-aware attention to identify the most similar datasets, and first  transfers trial observations,  neural processes parameters, and initial hyperparameter configurations collectively from these datasets.
              </div><br>

             
              <div onmouseover="document.getElementById('e2e').style.display = 'block';" onmouseout="document.getElementById('e2e').style.display='none';">
                <papertitle>Transferable End-to-End Aspect-based Sentiment Analysis with Selective Adversarial Learning</papertitle></a><br>
              <a href="https://hsqmlzno1.github.io/">Zheng Li</a>,
              <a href="https://lixin4ever.github.io/">Xin Li</a>, 
              <i>Ying Wei</i>,
              <a href="https://lidongbing.github.io/">Lidong Bing</a>,
              <a href="https://yuzhanghk.github.io/">Yu Zhang</a>,  
              <a href="http://www.cs.ust.hk/~qyang/">Qiang Yang</a>  
              <br>
              <em>2019 Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>, 2019 <br>
              <a href="https://www.aclweb.org/anthology/D19-1466.pdf">pdf</a>  / <a href="https://github.com/hsqmlzno1/Transferable-E2E-ABSA">code</a>
            </div>
              <div id="e2e" style="display: none;">
             Jointly extracting aspects and sentiments for sentiment classification requires considerable labeled sentences which are highly labor-intensive. We innovatively alleviate the problem via unsupervised domain adaptation from a sufficiently labeled domain. We propose a  novel  selective  adversarial  learning  method  to learn correlation  vectors between aspects and sentiments and attentively  transfer them across domains.
              </div><br>


              <div onmouseover="document.getElementById('dman').style.display = 'block';" onmouseout="document.getElementById('dman').style.display='none';">
                <papertitle>From Whole Slide Imaging to Microscopy: Deep Microscopy Adaptation Network for
Histopathology Cancer Image Classification</papertitle></a><br>
              <a href="https://sites.google.com/view/yifan-zhang/%E9%A6%96%E9%A1%B5"><u>Yifan Zhang</u></a>,
              <a href="http://cobweb.cs.uga.edu/~hanbo/"><u>Hanbo Chen</u></a>, 
              <i><u>Ying Wei</u></i>,
              <a href="http://peilinzhao.weebly.com/">Peilin Zhao</a>, 
              Jiezhang Cao, Xinjuan  Fan, Xiaoying  Lou,  Hailing  Liu,  Jinlong  Hou,  Xiao  Han,  Jianhua  Yao,  Qingyao  Wu, 
              <a href="http://www.tanmingkui.com/">Mingkui Tan</a>,  
              <a href="http://ranger.uta.edu/~huang/">Junzhou Huang</a>
              <br>
              <em>22nd International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI)</em>, 2019 <br>
              <a href="https://www.researchgate.net/profile/Yifan_Zhang145/publication/336399576_From_Whole_Slide_Imaging_to_Microscopy_Deep_Microscopy_Adaptation_Network_for_Histopathology_Cancer_Image_Classification/links/5de62654a6fdcc2837009f48/From-Whole-Slide-Imaging-to-Microscopy-Deep-Microscopy-Adaptation-Network-for-Histopathology-Cancer-Image-Classification.pdf">pdf</a>
            </div>
              <div id="dman" style="display: none;">
             This work is the first to empower digital pathology image classification directly based on microscopy images. Specifically, we resort to unsupervised domain adaptation from whole slide images to remedy the lack of annotated microscopy images. The proposed resolves intra-domain discrepancy and class imbalance via entropy minimization and sample re-weighting, respectively, besides inter-domain discrepancy.              
         </div><br>


              <div onmouseover="document.getElementById('hsml').style.display = 'block';" onmouseout="document.getElementById('hsml').style.display='none';">
              	<a href="http://proceedings.mlr.press/v97/yao19b.html">
                <papertitle>Hierarchically Structured Meta-learning</papertitle></a><br>
              <a href="http://huaxiuyao.mystrikingly.com/">Huaxiu Yao</a>,
              <i>Ying Wei*</i>,
              <a href="http://ranger.uta.edu/~huang/">Junzhou Huang</a>,
              <a href="https://faculty.ist.psu.edu/jessieli/Site/index.html">Zhenhui Li</a> 
              <br>
              <em>36th International Conference on Machine Learning (ICML)</em>, 2019 <br>
              <a href="http://proceedings.mlr.press/v97/yao19b/yao19b.pdf">pdf</a> / <a href="https://github.com/huaxiuyao/hsml_2019">code</a>
            </div>
              <div id="hsml" style="display: none;">
             We devote to conquering a critical challenge in meta-learning, namely task uncertainty and heterogeneity, where tasks may be originated from wildly different distributions. We propose a highly-motivated meta-learning algorithm with hierarchical task clustering. It not only alleviates task heterogeneity via  knowledge customization to different clusters of tasks, but also preserves knowledge generalization among a cluster of similar tasks.
              </div><br>


              <div onmouseover="document.getElementById('metast').style.display = 'block';" onmouseout="document.getElementById('metast').style.display='none';">
              	<a href="https://arxiv.org/abs/1901.08518">
                <papertitle>Learning from Multiple Cities: A Meta-Learning Approach for Spatial-Temporal Prediction</papertitle></a><br>
              <a href="http://huaxiuyao.mystrikingly.com/">Huaxiu Yao</a>,
              Yiding Liu, 
              <i>Ying Wei</i>,
              Xianfeng Tang,
              <a href="https://faculty.ist.psu.edu/jessieli/Site/index.html">Zhenhui Li</a> 
              <br>
              <em>The Web Conference (WWW)</em>, 2019 <br>
              <a href="https://arxiv.org/pdf/1901.08518.pdf">pdf</a> / <a href="https://github.com/huaxiuyao/MetaST">code</a>
            </div>
              <div id="metast" style="display: none;">
             This work improves spatial-temporal prediction tasks like traffic prediction for those cities with only limited training data in a short period. The improvement is attributed to the knowledge  transferred from other cities with sufficient data covering long periods. We first introduce the meta-learning paradigm into spatial-temporal prediction, and formulate the transferable knowledge as both short-term and long-term spatial-temporal patterns which are represented as model parameters and an explicit memory, respectively. 
              </div><br>

              <div onmouseover="document.getElementById('c2f').style.display = 'block';" onmouseout="document.getElementById('c2f').style.display='none';">
              	<a href="https://arxiv.org/abs/1811.10999">
                <papertitle>Exploiting Coarse-to-Fine Task Transfer for Aspect-Level Sentiment Classification</papertitle></a><br>
              <a href="https://hsqmlzno1.github.io/">Zheng Li</a>,
              <i>Ying Wei</i>,
              <a href="https://yuzhanghk.github.io/">Yu Zhang</a>,  
              Xiang Zhang, 
              <a href="https://lixin4ever.github.io/">Xin Li</a> 
              <br>
              <em>33rd AAAI Conference on Artificial Intelligence (AAAI) </em>, 2019 <br>
              <a href="https://arxiv.org/pdf/1811.10999.pdf">pdf</a> / <a href="https://github.com/hsqmlzno1/MGAN">code</a>
            </div>
              <div id="c2f" style="display: none;">
             We aim at identifying sentiment towards aspect terms in a sentence, while  annotating sentences in this case is prohibitively expensive. Innovatively,  we leverage knowledge from more easily accessible sentences whose sentiment is annotated to aspect categories. We propose a multi-granularity alignment network to achieve domain adaptation, which resolves both aspect granularity inconsistency and feature discrepancy between domains.
              </div><br>

              <div onmouseover="document.getElementById('l2mt').style.display = 'block';" onmouseout="document.getElementById('l2mt').style.display='none';">
                <a href="https://papers.nips.cc/paper/7819-learning-to-multitask">
                <papertitle>Learning to Multitask</papertitle></a><br>
              <a href="https://yuzhanghk.github.io/">Yu Zhang</a>,
              <i>Ying Wei</i>,
              <a href="http://www.cs.ust.hk/~qyang/">Qiang Yang</a>  
              <br>
              <em>32nd Annual Conference on Neural Information Processing Systems (NeurIPS)</em>, 2018 <br>
              <a href="https://papers.nips.cc/paper/7819-learning-to-multitask.pdf">pdf</a>
            </div>
              <div id="l2mt" style="display: none;">
             This work is the pioneer in automatically identifying an effective multitask model for a multitask problem, empowered by a groundbreaking learning to multitask framework.
              </div><br>

              <div onmouseover="document.getElementById('l2t').style.display = 'block';" onmouseout="document.getElementById('l2t').style.display='none';">
                <a href="http://proceedings.mlr.press/v80/wei18a.html">
                <papertitle>Transfer learning via Learning to Transfer</papertitle></a><br>
              <i>Ying Wei</i>,
              <a href="https://yuzhanghk.github.io/">Yu Zhang</a>,
              <a href="http://ranger.uta.edu/~huang/">Junzhou Huang</a>,            
              <a href="http://www.cs.ust.hk/~qyang/">Qiang Yang</a>  
              <br>
              <em>35th International Conference on Machine Learning (ICML)</em>, 2018 (<newsdate>long talk</newsdate>)<br>
              <a href="http://proceedings.mlr.press/v80/wei18a/wei18a.pdf">pdf</a>
            </div>
              <div id="l2t" style="display: none;">
             This work opens a new door to improve transfer learning effectiveness. We propose a groundbreaking learning to transfer framework to automatically optimize what and how to transfer across domains, by taking advantage of previous transfer learning experiences.
              </div><br>  

              <div onmouseover="document.getElementById('hatn').style.display = 'block';" onmouseout="document.getElementById('hatn').style.display='none';">
                <a href="https://aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16873">
                <papertitle>Hierarchical Attention Transfer Network for Cross-domain Sentiment Classification</papertitle></a><br>
              <a href="https://hsqmlzno1.github.io/">Zheng Li</a>,
              <i>Ying Wei</i>,
              <a href="https://yuzhanghk.github.io/">Yu Zhang</a>,  
              <a href="http://www.cs.ust.hk/~qyang/">Qiang Yang</a>  
              <br>
              <em>32nd AAAI Conference on Artificial Intelligence (AAAI)</em>, 2018 <br>
              <a href="https://aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16873/16149">pdf</a> / <a href="https://github.com/hsqmlzno1/HATN">code</a>
            </div>
              <div id="hatn" style="display: none;">
             We are dedicated to improve cross-domain sentiment classification, from the perspectives of discovering domain-invariant emotion words of higher quality for knowledge transfer as well as capturing domain-specific emotion words for sentiment classification. The proposed hierarchical attention transfer network achieves the two goals with a  hierarchical attention mechanism and a non-pivots network, respectively.
              </div><br>       

              <div onmouseover="document.getElementById('tcb').style.display = 'block';" onmouseout="document.getElementById('tcb').style.display='none';">
                <a href="https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16692/">
                <papertitle>Transferable Contextual Bandit for Cross-Domain Recommendation</papertitle></a><br>
              <a href="http://boliu68.github.io/about/">Bo Liu</a>,
              <i>Ying Wei</i>,
              <a href="https://yuzhanghk.github.io/">Yu Zhang</a>,  
              <a href="http://www.cs.ust.hk/~qyang/">Qiang Yang</a>
              <br>
              <em>32nd AAAI Conference on Artificial Intelligence (AAAI)</em>, 2018 <br>
              <a href="https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16692/16564">pdf</a>
            </div>
              <div id="tcb" style="display: none;">
             Though contextual bandit effectively solves the exploitation-exploration dilemma in recommendation systems, it suffers from over-exploration in the cold-start scenario. This work is the first to alleviate the problem by transferring knowledge from other domains. We propose a transferable contextual bandit policy which transfers observations to improve user interests estimation for exploitation and thus accelerates the exploration.transfer network achieves the two goals with a  hierarchical attention mechanism and a non-pivots network, respectively.
              </div><br>   

              <div onmouseover="document.getElementById('l2t_arxiv').style.display = 'block';" onmouseout="document.getElementById('l2t_arxiv').style.display='none';">
                <a href="https://arxiv.org/abs/1708.05629">
                <papertitle>Learning to Transfer</papertitle></a><br>
              <i>Ying Wei</i>,
              <a href="https://yuzhanghk.github.io/">Yu Zhang</a>,  
              <a href="http://www.cs.ust.hk/~qyang/">Qiang Yang</a>
              <br>
              <a href="https://arxiv.org/pdf/1708.05629.pdf">arXiv</a>
            </div>
              <div id="l2t_arxiv" style="display: none;">
             Highly motivated by human beings' capabilities to reflect on transfer learning experiences, we propose a novel transfer learning framework to learn meta-knowledge from historical transfer learning experiences and apply the meta-knowledge to automatically optimize what to transfer in the future.
              </div><br> 

              <div onmouseover="document.getElementById('amn').style.display = 'block';" onmouseout="document.getElementById('amn').style.display='none';">
                <a href="https://www.ijcai.org/proceedings/2017/0311">
                <papertitle>End-to-End Adversarial Memory Network for Cross-domain Sentiment Classification</papertitle></a><br>
              <a href="https://hsqmlzno1.github.io/">Zheng Li</a>,
              <a href="https://yuzhanghk.github.io/">Yu Zhang</a>,  
              <i>Ying Wei</i>,
              <a href="http://www.cs.ust.hk/~qyang/">Qiang Yang</a>  
              <br>
              <em>26th International Joint Conference on Artificial Intelligence (IJCAI)</em>, 2017 <br>
              <a href="https://www.ijcai.org/proceedings/2017/0311.pdf">pdf</a> / <a href="https://github.com/hsqmlzno1/HATN">code</a>
            </div>
              <div id="amn" style="display: none;">
             This work focuses on cross-domain sentiment classification, e.g., sentiment classification of book reviews by transferring knowledge from electronics product reviews. The key here is to identify domain-invariant emotion words as the transferable knowledge. We are the first to automatically learn domain-invariant emotion words by introducing  an end-to-end adversarial memory network and offer a direct visualization of them.
              </div><br> 

              <div onmouseover="document.getElementById('dnn').style.display = 'block';" onmouseout="document.getElementById('dnn').style.display='none';">
                <a href="https://www.ijcai.org/proceedings/2017/0318">
                <papertitle>Deep Neural Networks for High Dimension, Low Sample Size Data</papertitle></a><br>
              <a href="http://boliu68.github.io/about/">Bo Liu</a>,
              <i>Ying Wei</i>,
              <a href="https://yuzhanghk.github.io/">Yu Zhang</a>,  
              <a href="http://www.cs.ust.hk/~qyang/">Qiang Yang</a>
              <br>
              <em>26th International Joint Conference on Artificial Intelligence (IJCAI)</em>, 2017 <br>
              <a href="https://www.ijcai.org/proceedings/2017/0318.pdf">pdf</a>
            </div>
              <div id="dnn" style="display: none;">
             We devote to address the problems of overfitting and high-variance gradients, when training deep neural networks on high dimension but low sample size data such as genetic data for phenotype prediction in bioinformatics. We propose a deep neural pursuit network which alleviates overfitting by selecting a subset of features and reduces variance by averaging the gradients over multiple dropouts.
              </div><br>   

              <div onmouseover="document.getElementById('hth_journal').style.display = 'block';" onmouseout="document.getElementById('hth_journal').style.display='none';">
              <a href="https://dl.acm.org/citation.cfm?id=2744204">
              <papertitle>Heterogeneous Translated Hashing: A Scalable Solution towards Multi-modal Similarity Search</papertitle></a><br>
              <i>Ying Wei</i>,
              <a href="https://www.cse.ust.hk/~yqsong/">Yangqiu Song</a>,
              <i>Yi Zhen</i>,
              <a href="http://boliu68.github.io/about/">Bo Liu</a>,              
              <a href="http://www.cs.ust.hk/~qyang/">Qiang Yang</a>  
              <br>
              <em>ACM Transactions on Knowledge Discovery from Data (TKDD)</em>, 10(4):36, 2016 <br>
              <a href="pubs/HTH_journal.pdf">pdf</a>
            </div>
              <div id="hth_journal" style="display: none;">
             This work provides a theoretical analysis and guarantee for the scalable heterogeneous translated hashing method which is proposed to build the correspondence between heterogeneous domains.
              </div><br> 

              <div onmouseover="document.getElementById('floral').style.display = 'block';" onmouseout="document.getElementById('floral').style.display='none';">
                <a href="https://dl.acm.org/citation.cfm?id=2939830">
                <papertitle>Transfer Knowledge between Cities</papertitle></a><br>
              <i>Ying Wei</i>,
              <a href="http://urban-computing.com/yuzheng">Yu Zheng</a>,
              <a href="http://www.cs.ust.hk/~qyang/">Qiang Yang</a>  
              <br>
              <em>22nd ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD)</em>, 2016 <br>
              <a href="pubs/FLORAL.pdf">pdf</a>
            </div>
              <div id="floral" style="display: none;">
             We propose the first principled approach to transfer knowledge between domains, each of which comprises multiple modalities of datasets. We conduct a case study of air quality prediction --  borrowing knowledge from the cities with sufficient annotations and data to the cities with either scarce annotations or insufficient data in any modality. The proposed method formulates the transferable knowledge as semantically related dictionaries for multiple modalities learned from a source domain and labeled examples.
              </div><br>  

              <div onmouseover="document.getElementById('htl').style.display = 'block';" onmouseout="document.getElementById('htl').style.display='none';">
                <a href="https://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/view/12308">
                <papertitle>Instilling Social to Physical: Co-Regularized Heterogeneous Transfer Learning</papertitle></a><br>
              <i>Ying Wei</i>,
              <a href="http://www.cse.ust.hk/~yinz/">Yin Zhu</a>,   
              <i>Cane Wing-ki Leung</i>           
              <a href="https://www.cse.ust.hk/~yqsong/">Yangqiu Song</a>,
              <a href="http://www.cs.ust.hk/~qyang/">Qiang Yang</a>  
              <br>
              <em>30th AAAI Conference on Artificial Intelligence (AAAI)</em>, 2016 <br>
              <a href="https://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/download/12308/11742">pdf</a>
            </div>
              <div id="htl" style="display: none;">
             This work first transfers knowledge from posts in the social media side to sensors in the physical world to improve ubiquitous computing tasks such as activity recognition. We propose a co-regularized heterogeneous transfer learning model to discover the transferable feature representations that bridge two domains in heterogeneous representation structures, co-regularized by both correspondence and labels.
              </div><br>  

              <div onmouseover="document.getElementById('hth').style.display = 'block';" onmouseout="document.getElementById('hth').style.display='none';">
              <a href="https://dl.acm.org/citation.cfm?id=2623330.2623688">
              <papertitle>Scalable Heterogeneous Translated Hashing</papertitle></a><br>
              <i>Ying Wei</i>,
              <a href="https://www.cse.ust.hk/~yqsong/">Yangqiu Song</a>,
              <i>Yi Zhen</i>,
              <a href="http://boliu68.github.io/about/">Bo Liu</a>,              
              <a href="http://www.cs.ust.hk/~qyang/">Qiang Yang</a>  
              <br>
              <em>20th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD)</em>, 2014 <br>
              <strong style="color:#E76F51">Best Paper Finalist</strong><br>
              <a href="pubs/HTH.pdf">pdf</a>
            </div>
              <div id="hth" style="display: none;">
             Knowledge transfer between domains that lie in heterogeneous feature spaces but have no access to explicit correspondence is almost impossible. This work is the pioneer in using hashing to  build the correspondence between such domains. The proposed method simultaneously learns hash functions embedding heterogeneous domains into different Hamming spaces, and a translator aligning these spaces.
              </div><br> 

     <hr>

    <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=200&t=tt&d=8NmGTlvpz2ZvkmJMCe85M51sBHI36O4bGHTb2_M14mc&co=2ca25f&cmo=e76f51&cmn=f0d650'></script>
    
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td>
              <br>
              <p align="right">
                <font size="2">
                  The source code of this website is adapted from both <a href="https://jonbarron.info/">this</a> and <a href="http://ai.stanford.edu/~cbfinn/">this page</a>.
              </p>
            </td>
          </tr>
        </table>

</td>

</tbody></table>

</html>
